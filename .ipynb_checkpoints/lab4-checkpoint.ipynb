{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Лабораторная работа №4\n",
    "_Анализ и визуализация данных в Python_\n",
    "\n",
    "Для начала о том, как пользоваться интерактивным блокнотом. Код помещается в ячейки, для выполнения кода в ячейке нужно кликнуть в ней мышкой, чтобы она выделилась, и нажать Shift-Enter. Поэкспериментируйте на ячейке ниже:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "1+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если в ячейке находятся несколько выражений, то результатом выполнения ячейки будет результат последнего выражения в ней:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "1+1\n",
    "1+2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь перейдём к работе с наборами данных при помощи бибилиотеки pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas\n",
    "Для того, чтобы начать работать с pandas, как и всегда в python, его нужно импортировать. Обычно это делают так:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь попробуем загрузить набор данных. Для примера возьмём titanic.csv из каталога datasets, который можно загрузить при помощи функции read_csv:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('datasets/titanic.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Взглянем на загруженные данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно попробовать найти в этих данных что-нибудь интересное. Например, посчитаем, какое количество мужчин и женщин было на корабле. Информация об этом хранится в столбце Sex, доступ к которому можно получить следующими способами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.Sex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "или"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Sex']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы посчитать количество мужчин и женщин воспользуемся методом value_counts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.Sex.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можем также получить процентное соотношение, указав флаг normalize:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.Sex.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можем определить среднюю цену билета, обратившись к столбцу Fare и воспользовавшись методом mean:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.Fare.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Из нашего набора данных можно построить новый, выбрав только нужные столбцы при помощи свойства loc, например"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = data.loc[:,['Name', 'Age']]\n",
    "new_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно отфильтровать только выживших"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "survived = new_data[data.Survived==1]\n",
    "survived"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Полученный набор данных можно экспортировать обратно в csv функцией to_csv:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "survived.to_csv('survived.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numpy\n",
    "Numpy -- это библиотека для работы с массивами в Python. Список из стандартной библиотеки не достаточно производителен и имеет достаточно скудный интерфейс, чтобы использовать его для научных вычислений. Начнём с импорта библиотеки, который обычно записывают так:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим массив"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.array([1,2,3,4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ровно как и с питоновскими списками можно получать элемент по индексу и делать слайсы:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr[2:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Но можно и доставать элементы по спи"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А можно сделать из него матрицу 2x2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = arr.reshape((2,2))\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно транспонировать эту матрицу"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вот так можно получить доступ к первой строке матрицы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А вот так -- ко второму столбцу:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Но самое интересное -- это применение операции ко всему массиву сразу. Например:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = arr * 2\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = arr + 1\n",
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно даже применять арифметические операции для двух массивов поэлементно, при условии, что их размеры совпадают:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a - b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a * b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a / b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a ** b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для нахождения скалярного произведения двух векторов есть оператор @"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a @ b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Он же отвечает за умножение матрицы на вектор и перемножение матриц по правилу строка на столбец:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m @ a[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m @ m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также массив позволяет находить статистические характеристики"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr.sum(), arr.mean(), arr.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно фильтровать элементы массива по условию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr[arr < 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matplotlib\n",
    "Для визуализации данных в python есть пакет matplotlib. Обычно его импортируют так:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вторая строчка нужна для того, чтобы графики отображались прямо в блокноте, а не в отдельном окне. Давайте что-нибудь построим:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x = np.linspace(0, 2*np.pi, 100)\n",
    "plt.plot(x, np.sin(x))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(0, 2*np.pi, 100)\n",
    "y = np.linspace(0, np.pi, 50)\n",
    "xx, yy = np.meshgrid(x, y)\n",
    "zz = np.sin(xx) * np.cos(yy)\n",
    "plt.contourf(xx, yy, zz, levels=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(0, 10, 100)\n",
    "y = np.sin(x) + 0.1 * x\n",
    "plt.scatter(x + np.random.rand(*x.shape), y + np.random.rand(*x.shape))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scikit-learn\n",
    "А теперь немного машинного обучения со scikit-learn. Рассмотрим примеры задач классификации с использованием решающих деревьев, метода k ближайших соседей, а также линейную регрессию."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Решающие деревья\n",
    "Рассмотрим знакомый уже нам набор данных о пассажирах титаника. Будем решать на них задачу классификации, в которой по различным характеристикам пассажиров требуется предсказать, кто из них выжил после крушения корабля и на основании полученной модели определим наиболее важные для выживания признаки.\n",
    "\n",
    "Для начала импортируем классификатор"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь подготовим данные. Для начала импортируем их и оставим только такие признаки как пол, класс, цена билета и возраст. В качестве целевой переменной у нас будет факт выживания:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('datasets/titanic.csv')\n",
    "interesting = data.loc[:, ['Sex', 'Pclass', 'Fare', 'Age', 'Survived']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обратим внимание, что имеются пропуски в данных. Избавимся от них, удалив соответствующие строки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interesting.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь отделим признаки от целевой переменной"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = interesting.iloc[:, :-1]\n",
    "y = interesting.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Заметим, что столбец Sex содержит текстовые данные и преобразуем их к числовым"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.Sex = X.Sex.map(lambda x: 0 if x == 'female' else 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим классификатор"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на его результаты на обучающей выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = clf.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "и определим долю правильных ответов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y, prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Метод k ближайших соседей\n",
    "Сейчас мы будем подбирать оптимальное значение k для алгоритма kNN. Будем использовать набор данных Wine, где требуется предсказать сорт винограда, из которого изготовлено вино, используя результаты химических анализов\n",
    "\n",
    "Начинаем с импорта классификатора"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузим данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('datasets/wine.csv', header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Класс записан в первом столбце (три варианта), признаки — в столбцах со второго по последний."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.iloc[:, 1:]\n",
    "y = data.iloc[:, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для данного метода настраиваемым параметром является количество ближайших соседей k. Для определения качества классификации и оптимального количества соседей будем рассчитывать точность классификации на кросс-валидации для количества соседей в диапазоне от 1 до 50.\n",
    "\n",
    "Создадим генератор разбиений для проведения кросс-валидации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "cv = KFold(y.size, n_splits=5, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И с помощью GridSearchCV будем искать оптимальное значение k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "grid = {'n_neighbors': np.arange(50) + 1}\n",
    "clf = KNeighborsClassifier()\n",
    "gs = GridSearchCV(clf, grid, scoring='accuracy', cv=cv)\n",
    "gs.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оптимальное значение количества соседей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А точность при этом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Логистическая регрессия\n",
    "\n",
    "Ещё одним способом классификации, несмотря на слово \"регрессия\" в названии, является логистическая регрессия. Одной из ее особенностей является возможность оценивания вероятностей классов, тогда как большинство линейных классификаторов могут выдавать только номера классов.\n",
    "\n",
    "Загрузим данные:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('datasets/data-logistic.csv', header=None)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Импортируем классификатор"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression(C=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим классификатор"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(data.iloc[:,1:], data.iloc[:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Визуализируем результат"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx,yy = np.meshgrid(np.linspace(data.iloc[:,1].min(), data.iloc[:,1].max(), 100),\n",
    "                    np.linspace(data.iloc[:,2].min(), data.iloc[:,2].max(), 100))\n",
    "zz = clf.predict(np.column_stack((xx.ravel(), yy.ravel())))\n",
    "zz = zz.reshape(xx.shape)\n",
    "plt.contourf(xx, yy, zz, levels=100)\n",
    "plt.scatter(data[data[0]==-1].iloc[:,1], data[data[0]==-1].iloc[:,2], marker='v')\n",
    "plt.scatter(data[data[0]==1].iloc[:,1], data[data[0]==1].iloc[:,2], marker='^')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Определим качество классификации при помощи метрики ROC-AUC:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "roc_auc_score(data[0], clf.predict(data.iloc[:, 1:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Линейная регрессия\n",
    "А сейчас мы будем предсказывать зарплату по описанию вакансии! Начнём с загрузки данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('datasets/salary-train.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подготовим данные. Для начала преобразуем все слова в столбце FullDescription в нижний регистр и заменим все спецсимволы на пробелы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.FullDescription = data.FullDescription.str.lower()\n",
    "data.FullDescription = data.FullDescription.replace('[^a-zA-Z0-9]', ' ', regex = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь заменим все пропущенные данные в столбцах LocationNormalized и ContractTime на 'nan':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['LocationNormalized'].fillna('nan', inplace=True)\n",
    "data['ContractTime'].fillna('nan', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь нам нужно преобразовать текст из столбца FullDescription в набор признаков. Одним из способов это сделать является TfidVectorizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfid = TfidfVectorizer(min_df=5)\n",
    "X_train_tfid = tfid.fit_transform(data.FullDescription)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы представить в виде набора числовых признаков содержимое столбцов LocationNormalized и ContractTime воспользуемся DictVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "enc = DictVectorizer()\n",
    "X_train_categ = enc.fit_transform(data[['LocationNormalized', 'ContractTime']].to_dict('records'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Объединим матрицы признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import hstack\n",
    "X = hstack((X_train_categ, X_train_tfid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим на этих признаках регрессор"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "reg = Ridge(alpha=1)\n",
    "reg.fit(X, data.SalaryNormalized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузим и преобразуем тестовые данные тем же образом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('datasets/salary-test-mini.csv')\n",
    "test.FullDescription = test.FullDescription.str.lower()\n",
    "test.FullDescription = test.FullDescription.replace('[^a-zA-Z0-9]', ' ', regex = True)\n",
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выделим признаки и получим предсказания зарплат"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_tfid = tfid.transform(test.FullDescription)\n",
    "X_test_categ = enc.transform(test[['LocationNormalized', 'ContractTime']].to_dict('records'))\n",
    "X_test = hstack((X_test_categ, X_test_tfid))\n",
    "\n",
    "test.SalaryNormalized = reg.predict(X_test)\n",
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Определить долю выживших и определите 2 наиболее важных признака для выживания при помощи DecisionTreeСlassifier на основе данных из datasets/titanic.csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "clf = DecisionTreeClassifier()\n",
    "\n",
    "data = pd.read_csv('datasets/titanic.csv')\n",
    "data2 = data.loc[:, ['Survived']]\n",
    "print(data2)\n",
    "\n",
    "#Количество выживших\n",
    "survived_count = np.sum(data2)\n",
    "\n",
    "#Доля выживших\n",
    "survived = survived_count/891\n",
    "print(survived)\n",
    "\n",
    "#Отбор 2-х признаков\n",
    "data3 = data.loc[:, ['Sex', 'Pclass', 'Fare', 'Age', 'Survived']]\n",
    "data3.dropna(inplace=True)\n",
    "X = data3.iloc[:, :-1]\n",
    "y = data3.iloc[:, -1]\n",
    "X.Sex = X.Sex.map(lambda x: 0 if x == 'female' else 1)\n",
    "\n",
    "model = ExtraTreesClassifier()\n",
    "model.fit(X, y)\n",
    "print(model.feature_importances_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для задачи о классификации вина методом ближайших соседей произведите масштабирование признаков с помощью функции sklearn.preprocessing.scale. Снова найдите оптимальное k на кросс-валидации. Помогло ли масштабирование?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import sklearn\n",
    "data = pd.read_csv('datasets/wine.csv', header=None)\n",
    "\n",
    "X = data.iloc[:, 1:]\n",
    "y = data.iloc[:, 0]\n",
    "\n",
    "#Проведем масштабирование факторов\n",
    "X = sklearn.preprocessing.scale(X)\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "cv = KFold(y.size, n_splits=5, shuffle=True)\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "grid = {'n_neighbors': np.arange(50) + 1}\n",
    "clf = KNeighborsClassifier()\n",
    "gs = GridSearchCV(clf, grid, scoring='accuracy', cv=cv)\n",
    "gs.fit(X, y)\n",
    "\n",
    "gs.best_params_\n",
    "gs.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Масштабирование помогло. Результат увеличился."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Определить качество линейной регрессии в примере с зарплатами при помощи метрики r2_score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "data = pd.read_csv('datasets/salary-train.csv')\n",
    "data\n",
    "\n",
    "data.FullDescription = data.FullDescription.str.lower()\n",
    "data.FullDescription = data.FullDescription.replace('[^a-zA-Z0-9]', ' ', regex = True)\n",
    "\n",
    "data['LocationNormalized'].fillna('nan', inplace=True)\n",
    "data['ContractTime'].fillna('nan', inplace=True)\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfid = TfidfVectorizer(min_df=5)\n",
    "X_train_tfid = tfid.fit_transform(data.FullDescription)\n",
    "\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "enc = DictVectorizer()\n",
    "X_train_categ = enc.fit_transform(data[['LocationNormalized', 'ContractTime']].to_dict('records'))\n",
    "\n",
    "from scipy.sparse import hstack\n",
    "X = hstack((X_train_categ, X_train_tfid))\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "reg = Ridge(alpha=1)\n",
    "reg.fit(X, data.SalaryNormalized)\n",
    "\n",
    "test = pd.read_csv('datasets/salary-train.csv')\n",
    "test.FullDescription = test.FullDescription.str.lower()\n",
    "test.FullDescription = test.FullDescription.replace('[^a-zA-Z0-9]', ' ', regex = True)\n",
    "test\n",
    "\n",
    "X_test_tfid = tfid.transform(test.FullDescription)\n",
    "X_test_categ = enc.transform(test[['LocationNormalized', 'ContractTime']].to_dict('records'))\n",
    "X_test = hstack((X_test_categ, X_test_tfid))\n",
    "\n",
    "test.SalaryNormalized = reg.predict(X_test)\n",
    "test\n",
    "\n",
    "out = sklearn.metrics.r2_score(data.SalaryNormalized,test.SalaryNormalized)\n",
    "print(data.SalaryNormalized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ИНДИВИДУАЛЬНОЕ ЗАДАНИЕ: \n",
    "Определите самое распространённое женское имя среди пассажиров Титаника. Извлеките из полного имени пассажира (колонка Name) его личное имя. Попробуйте вручную разобрать несколько значений столбца Name и выработать правило для извлечения имен, а также разделения их на женские и мужские."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('datasets/titanic.csv')\n",
    "fem = data.where(data.Sex==\"female\")\n",
    "fem = fem.Name\n",
    "fem.dropna(inplace=True)\n",
    "\n",
    "name = []\n",
    "for item in fem:\n",
    "    dot = item.split('. ')\n",
    "    \n",
    "    LP = dot[1].split('(')\n",
    "    if len(LP) == 2: \n",
    "        x = LP[1]\n",
    "    else:\n",
    "        x = LP[0]\n",
    "    mrs = x.split('\"Mrs ')\n",
    "    if len(mrs) == 2:\n",
    "        y = mrs[1]\n",
    "    else:\n",
    "        y = mrs[0]\n",
    "    space = y.split(' ')\n",
    "    RP = space[0].split(')')\n",
    "    name.append(RP[0])\n",
    "    \n",
    "df = pd.DataFrame(name) \n",
    "\n",
    "df[0].value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
